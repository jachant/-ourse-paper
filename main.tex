\documentclass[14pt]{article}
% \usepackage[14pt]{extsizes}
\usepackage[utf8]{inputenc}
\usepackage{amssymb,amsthm}
\usepackage{amsmath}
\theoremstyle{definition}
\newtheorem{definition}{Определение}
\usepackage[russian]{babel}
\usepackage[shortlabels]{enumitem}
\newtheorem{theorem}{\bf Теорема}
\usepackage{graphicx}
\usepackage[left=3cm, right=3cm, top=3cm, bottom=3cm]{geometry}
\setlength{\parindent}{0cm}
\newenvironment{ourproof}{\\ \textit{Доказательство.}\\ }{$\hfill \heartsuit$}
\usepackage{ amssymb }
\usepackage{ dsfont }
\newtheorem{exercise}{Упражнение}
\newtheorem{example}{Пример}
\setlength{\parindent}{5ex}
\newtheorem{rem}{Замечание}[section]
\newtheorem{proposition}{Предложение}[section]
\usepackage[T1]{fontenc}
\usepackage{ mathrsfs }
\usepackage{mathrsfs}
\usepackage{ upgreek }
\usepackage{wrapfig}
\usepackage{textcomp}

\linespread{1.5} 
\frenchspacing

    

\usepackage{xcolor}
\usepackage{hyperref}


\begin{document}


\begin{titlepage}
  \begin{center}
    \normalsize
   \textbf {Правительство Российской Федерации\\ 
Федеральное государственное автономное образовательное учреждение\\
   высшего профессионального образования\\
    «Национальный исследовательский университет» \\
     «Высшая школа экономики»}
   

    
    
    
    \textbf {Нижегородский филиал}
    
  \vfill
    Факультет математики, информатики и компьютерных наук\\
    
    
   
    \vfill

    \textbf{ КУРСОВАЯ РАБОТА}\\[5mm]
    
    {\normalsize  \textbf{О кодовых LLM и способах оценки качества моделей для класса задач
суммаризации кода}}
    
  \bigskip
    
    
\end{center}
\vfill

\newlength{\ML}
\settowidth{\ML}{«\underline{\hspace{0.7cm}}» 
\underline{\hspace{2cm}}}
\hfill
\begin{minipage}{0.5\textwidth}
  Выполнил:\\
 Студент 2 курса группы 23КНТ6    
   \\
 Антонов Артём Владимирович\\ 


 \\Научный руководитель:\\
 Сотрудник компании Yadro\\ 
Воевоводкин Вадим Сергеевич\\
  \vspace{1cm}
 {\hspace{2.5cm}}
\end{minipage}%
\vfill

\begin{center}
  Нижний Новгород\\Май 2025 г.
\end{center}

\end{titlepage}

\pagebreake[2]


\newpage
\tableofcontents
\newpage
\section{Введение}
В современном мире большие языковые модели стали неотъемлемой частью повседневной жизни. Они используются в различных сферах деятельности, таких как образование, бизнес, наука и технологии. В этой работе мы рассмотрим основные аспекты применения больших языковых моделей и их влияние на нашу жизнь.

Большие языковые модели представляют собой мощные инструменты, способные обрабатывать огромные объёмы текста и генерировать тексты, которые могут быть полезны для решения различных задач. Они основаны на глубоком обучении и используют огромные объёмы данных для обучения.

Одним из способов повышения эффективности работы с большими языковыми моделями является обобщение кода. Обобщение кода — это процесс преобразования исходного кода в более общий или абстрактный вид, который может быть использован для решения множества задач. Этот метод позволяет разработчикам создавать более универсальные и гибкие программы, которые могут быть адаптированы к различным контекстам и требованиям.

Обобщение кода (преобразование кода в текст): Целью задачи обобщения кода является генерация
описаний кода на естественном языке, который предоставляется в качестве входных данных. Мы выполняем эту задачу
двумя способами: генерируем сводку на уровне фрагмента, используя пары комментарий-фрагмент, и генерируем
сводку на уровне проблемы, используя пары описания проблемы и программного кода. Приложения
этой задачи включают повышение понятности раскомментированного или незнакомого кода для начинающих
пользователей и упрощение совместной работы, а также обучения.


//todo: definition 

We use the following metrics to evaluate different tasks proposed in this work: (i) BLEU (Papineni
et al., 2002) score to evaluate code-to-text generation tasks;, (ii) BLEU and CodeBLEU4 (Ren et al.,
2020) to evaluate code-to-code and text-to code generation tasks, and (iii) Mean Reciprocal Rank
(MRR) to evaluate retrieval tasks.

Задача исследования также включает сравнение различных датасетов и выявление причин, по которым два похожих датасета могут иметь разную популярность использования.

 
 \newpage
 \section{XLCoST: Cross-Language Code Snippet Transfer}

\subsection{Структура и особенности}
XLCoST (Cross-Language Code Snippet Transfer) — это мультиязычный датасет, разработанный для задач трансляции кода между языками программирования и генерации кода из текстовых описаний. Он содержит парные данные для 8 языков: Python, Java, C++, C\#, JavaScript, PHP, Go и Ruby. Каждая запись включает:

    
- Исходный код на одном языке.
    
- Соответствующий перевод на другой язык.
    
- Текстовое описание функционала на английском языке.


Датасет разделен на три подмножества:
\begin{enumerate}
    \item \textbf{Code-to-Code}: Пары кода на разных языках (например, Java ↔ C++).
    \item \textbf{Text-to-Code}: Описания на естественном языке и соответствующий код.
    \item \textbf{Documentation}: Расширенные комментарии и документация.
\end{enumerate}

Общий объем данных превышает 1.2 миллиона примеров, собранных из открытых репозиториев GitHub и Stack Overflow.

\subsection{Применение и исследования}
XLCoST используется для обучения моделей, способных выполнять:

    
- Трансляцию кода между языками (например, автоматический перенос алгоритма с Python на Java).
    
- Генерацию кода из текстовых спецификаций.
    
- Синхронизацию документации при изменении кодовой базы.


Особенность датасета — акцент на параллельность данных, что позволяет исследовать кросс-языковые зависимости. Например, в работе Ming Zhu et al. (2022) модель на основе XLCoST демонстрирует точность 78\% в задачах перевода между Java и Python.

Датасет активно применяется в исследованиях мультиязычных моделей, таких как CodeBERT и PLBART, а также в коммерческих инструментах рефакторинга.

\subsubsection*{Ссылки}
\href{https://arxiv.org/abs/2203.04225}{Zhu, M., et al. "XLCoST: A Benchmark Dataset for Cross-Language Code Snippet Transfer." arXiv:2203.04225 (2022)}.

\newpage

\section{CodeSearchNet: Семантический поиск кода}

\subsection{Структура и языки}
CodeSearchNet (CSN) — датасет, разработанный GitHub для обучения моделей семантического поиска кода. Он охватывает 6 языков: Python, JavaScript, Ruby, Go, Java, PHP. Каждая запись содержит:

    
- Фрагмент кода (функцию или метод).
    
- Текстовое описание его функционала (на английском языке).
    
- Метаданные (репозиторий, лицензия, звезды GitHub).


Объем данных — 2.3 миллиона пар код-описание, что делает CSN одним из крупнейших ресурсов для NLP-задач, связанных с кодом. Данные собраны из публичных репозиториев с лицензиями MIT, Apache 2.0 и GPL.

\subsection{Практическое использование}
CodeSearchNet решает две ключевые задачи:
\begin{enumerate}
    \item Поиск кода по текстовому запросу (например, "сортировка списка по убыванию").
    \item Генерация описаний для существующего кода.
\end{enumerate}

Датасет стал основой для моделей вроде CodeBERT и UniXcoder, которые используются в GitHub Copilot для предложения релевантных фрагментов кода. В исследовании Husain et al. (2019) модель на CSN достигла точности 72\% в поиске кода для Python.

\subsubsection*{Ссылки}
\href{https://arxiv.org/abs/1909.09436}{Husain, H., et al. "CodeSearchNet Challenge: Evaluating the State of Semantic Code Search." arXiv:1909.09436 (2019)}.

\newpage

\section{CodeXGLUE: Бенчмарк для оценки моделей}

\subsection{Архитектура и задачи}
CodeXGLUE (Code eXamination General Language Understanding Evaluation) — комплексный бенчмарк от Microsoft, включающий 11 задач для оценки моделей обработки кода:

    
- Code Completion (автодополнение).
    
- Code Repair (исправление ошибок).
    
- Text-to-Code Generation (генерация кода из текста).
    
- Code Translation (перевод между языками).


Датасет поддерживает языки: Python, Java, C\#, JavaScript и PHP. Его структура объединяет несколько существующих ресурсов (например, CodeSearchNet) и добавляет новые, такие как Code2Seq для генерации последовательностей.

\subsection{Роль в исследованиях}
CodeXGLUE стандартизирует оценку моделей, таких как Codex (OpenAI) и GraphCodeBERT, позволяя сравнивать их эффективность. Например, в задаче исправления ошибок модель Codex достигает точности 64\%, тогда как специализированные модели (например, DeepDebug) показывают 71\% (Lu et al., 2021).

Датасет также включает метрики оценки (BLEU, Accuracy, F1) и лидерборды, что стимулирует конкуренцию в научном сообществе.

\subsubsection*{Ссылки}
\href{https://dl.acm.org/doi/10.1145/3484577}{Lu, S., et al. "CodeXGLUE: A Benchmark Dataset for Code Intelligence." ACM Transactions on Software Engineering and Methodology (2021)}.

\newpage

\section{Сравнение}
Все три датасета решают взаимодополняющие задачи:

    
- \textbf{XLCoST} фокусируется на мультиязычности и трансляции кода.
    
- \textbf{CodeSearchNet} оптимизирован для семантического поиска.
    
- \textbf{CodeXGLUE} обеспечивает стандартизацию оценки моделей.


Их объединяет использование данных из открытых источников (GitHub, Stack Overflow) и поддержка популярных языков (Python, Java). Однако XLCoST выделяется включением C++ и Ruby, а CodeXGLUE — разнообразием задач.

Эти датасеты стали основой для прорывов в генерации кода, например, в GitHub Copilot и Amazon CodeWhisperer. Дальнейшее развитие области связано с увеличением объема данных и улучшением обработки низкоресурсных языков (например, Kotlin).

\textbf{Перспективы:}

    
- Интеграция датасетов для создания универсальных моделей.
    
- Расширение поддержки языков для нишевых экосистем (Rust, Swift).
    
- Применение в образовании (автоматическая проверка заданий).


Таким образом, XLCoST, CodeSearchNet и CodeXGLUE играют ключевую роль в эволюции инструментов разработки и методов машинного обучения, связанных с кодом.



\newpage
 \section{part 2}
 
 
 




\newpage
\section{Заключение}





\newpage
\addcontentsline{toc}{section}{\bf{Список литературы}}
\begin{thebibliography}{99}

\bibitem{RuelTakens}Рюэль Д., Такенс Ф., О природе турбулентности. // в кн. “Странные аттракторы”, М.: Мир, 1981.

\bibitem{Lorenz1} Lorenz E.N., Deterministic nonperiodic flow. // J. of the Atmospheric Sciences, 1963, 20, 130-141 [Перевод на русский язык: Эдвард Н. Лоренц Детерминированное непериодическое течение – в кн. “Странные аттракторы”, М.: Мир, 1981.


\bibitem{SH3} Шильников Л.П., Теория бифуркаций и модель Лоренца.// Дополнение I к кни- ге Дж.Марсдена и М.Мак- Кракена “Бифуркация рождения цикла и ее приложения.” М., Мир, 1980.

\bibitem{ABSH2} Афраймович В.С., Быков В.В., Шильников Л.П., О притягивающих негрубых мно- жествах типа аттрактора Лоренца.// Труды ММО, 1982.

\bibitem{ABSH1} Афраймович В.С., Быков В.В., Шильников Л.П. О возникновении и структуре ат- трактора Лоренца.// ДАН СССР, 1977.

\bibitem{ShaShi} M. V. Shashkov, L. P. Shilnikov, “On the existence of a smooth invariant foliation in Lorenz-type mappings”, Differ. Uravn. (1994)

\bibitem{GonKazTur} Sergey Gonchenko , Alexey Kazakov,  Dmitry Turaev Wild pseudohyperbolic attractor in a four-dimensional Lorenz system. 2018

\bibitem{MalSaf} M. Malkin, K. Safonov Entropy charts and bifurcations for Lorenz maps with infinite derivatives.2021


\end{thebibliography}

\end{document}
